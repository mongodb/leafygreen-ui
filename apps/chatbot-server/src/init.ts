import {
  GenerateUserPromptFunc,
  makeRagGenerateUserPrompt,
  MakeUserMessageFunc,
} from 'mongodb-chatbot-server';
import {
  ChatLlm,
  ConversationsService,
  Embedder,
  makeDefaultFindContent,
  makeMongoDbConversationsService,
  makeMongoDbEmbeddedContentStore,
  makeOpenAiChatLlm,
  makeOpenAiEmbedder,
  MongoDbEmbeddedContentStore,
} from 'mongodb-rag-core';
import { MongoClient } from 'mongodb-rag-core/mongodb';
import { AzureOpenAI } from 'mongodb-rag-core/openai';

import { loadEnvVars } from './utils/loadEnv';

export async function initChatBot(): Promise<{
  llm: ChatLlm;
  embedder: Embedder;
  embeddedContentStore: MongoDbEmbeddedContentStore;
  generateUserPrompt: GenerateUserPromptFunc;
  mongodbClient: MongoClient;
  conversations: ConversationsService;
}> {
  const {
    MONGODB_CONNECTION_URI,
    MONGODB_DATABASE_NAME,
    VECTOR_SEARCH_INDEX_NAME,
    AZURE_OPENAI_ENDPOINT,
    AZURE_OPENAI_API_KEY,
    AZURE_OPENAI_EMBEDDING_MODEL,
    AZURE_OPENAI_CHAT_COMPLETION_MODEL,
  } = loadEnvVars();

  const azureOpenAIEmbeddingClient = new AzureOpenAI({
    endpoint: AZURE_OPENAI_ENDPOINT,
    apiKey: AZURE_OPENAI_API_KEY,
    apiVersion: '2024-04-01-preview',
    deployment: AZURE_OPENAI_EMBEDDING_MODEL,
  });

  const azureOpenAIChatClient = new AzureOpenAI({
    endpoint: AZURE_OPENAI_ENDPOINT,
    apiKey: AZURE_OPENAI_API_KEY,
    apiVersion: '2024-04-01-preview',
    deployment: AZURE_OPENAI_CHAT_COMPLETION_MODEL,
  });

  // Chatbot LLM for responding to the user's query.
  const llm = makeOpenAiChatLlm({
    openAiClient: azureOpenAIChatClient,
    deployment: AZURE_OPENAI_CHAT_COMPLETION_MODEL,
    openAiLmmConfigOptions: {
      temperature: 0.5,
    },
  });

  // Creates vector embeddings for user queries to find matching content
  // in the embeddedContentStore using Atlas Vector Search.
  const embedder: Embedder = makeOpenAiEmbedder({
    openAiClient: azureOpenAIEmbeddingClient,
    deployment: AZURE_OPENAI_EMBEDDING_MODEL,
    backoffOptions: {},
  });

  // MongoDB data source for the content used in RAG.
  // Generated with the Ingest CLI.
  const embeddedContentStore = makeMongoDbEmbeddedContentStore({
    connectionUri: MONGODB_CONNECTION_URI,
    databaseName: MONGODB_DATABASE_NAME,
    searchIndex: {
      embeddingName: AZURE_OPENAI_EMBEDDING_MODEL,
    },
  });

  // Find content in the embeddedContentStore using the vector embeddings
  // generated by the embedder.
  const findContent = makeDefaultFindContent({
    embedder,
    store: embeddedContentStore,
    findNearestNeighborsOptions: {
      k: 5,
      path: 'embeddings.text-embedding-3-small',
      indexName: VECTOR_SEARCH_INDEX_NAME,
      // Note: you may want to adjust the minScore depending
      // on the embedding model you use. We've found 0.9 works well
      // for OpenAI's text-embedding-ada-02 model for most use cases,
      // but you may want to adjust this value if you're using a different model.
      minScore: 0,
    },
  });

  // Constructs the user message sent to the LLM from the initial user message
  // and the content found by the findContent function.
  const makeUserMessage: MakeUserMessageFunc = async function ({
    content,
    originalUserMessage,
  }) {
    const chunkSeparator = '~~~~~~';
    const context = content.map(c => c.text).join(`\n${chunkSeparator}\n`);
    const contentForLlm = `Using the following information, answer the user query.
  Different pieces of information are separated by "${chunkSeparator}".
  
  Information:
  ${context}
  
  
  User query: ${originalUserMessage}`;
    return { role: 'user', content: contentForLlm };
  };

  // Generates the user prompt for the chatbot using RAG
  const generateUserPrompt: GenerateUserPromptFunc = makeRagGenerateUserPrompt({
    findContent,
    makeUserMessage,
  });

  // Create MongoDB collection and service for storing user conversations
  // with the chatbot.
  const mongodbClient = new MongoClient(MONGODB_CONNECTION_URI);
  const conversations = makeMongoDbConversationsService(
    mongodbClient.db(MONGODB_DATABASE_NAME),
  );

  return {
    llm,
    embedder,
    embeddedContentStore,
    generateUserPrompt,
    mongodbClient,
    conversations,
  };
}
